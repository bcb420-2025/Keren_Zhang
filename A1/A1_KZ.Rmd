---
title: "Assignment 1"
subtitle: "Data set selection and initial Processing"
author: "Keren Zhang"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 2
bibliography: A1_references.bib
csl: apa-6th-edition.csl
link-citations: TRUE
---

## Introduction

Lung adenocarcinoma, a major subtype of non-small cell lung cancer (NSCLC), is one of the most common and deadly forms of cancer worldwide[@zappa2016non]. Despite advances in treatment, many patients diagnosed with early-stage lung adenocarcinoma still face a high risk of the cancer spreading, or metastasizing, to other parts of the body after surgical removal of the tumor. This spread significantly worsens their prognosis and treatment options. Understanding the mechanisms of metastasis and resistance to therapy in lung adenocarcinoma is crucial for developing more effective treatments[@zappa2016non].

In the study by Liu et al. (2024), they particularly focused on lung adenocarcinoma (LUAD), which is a type of lung cancer known to spread to distant parts of the body in about half of the patients even after surgical removal of the tumor[@liu2024modeling]. To better understand and find ways to treat this spreading, or metastasis, they have developed a new experimental model using patient-derived organoids (PDOs). PDOs are three-dimensional cell cultures taken from patients' tumors that mimic the real biological environment of lung cancer. In addition to PDOs, the study also utilized metastasis-derived organoids (MDOs), which were harvested from different metastatic sites, including the brain, diaphragm, liver, and gallbladder, to model and investigate the mechanisms driving LUAD metastasis and potential therapeutic vulnerabilities.

## Data Import

#### Load Necessary Libraries:

```{r}
library(GEOquery)
library(knitr)
library(ggplot2)
library(edgeR)
library(biomaRt)
library(dplyr)
library(tidyr)
library(reshape2)

```

```{r}

data_set_geoid <- "GSE276387" 

# Obtain Data from GEO
gse <- getGEO(data_set_geoid ,GSEMatrix=FALSE)

#Sumamry of Dataset
gse@header$summary
```

### Additional information

#### Information about Platforms:

```{r}
# Check the number of platforms found
number_of_platforms <- length(names(GPLList(gse)))
print(paste("Number of platforms available:", number_of_platforms))

# Retrieve first platform IDs (GPL) associated with the GSE
gpl_1 <- names(GPLList(gse))[[1]]

print("First Platform:")
#Retrieve detailed information about the platform used in the GEO series
gpl_1_info <- Meta(getGEO(gpl_1))

gpl_1_info$title

gpl_1_info$last_update_date

gpl_1_info$organism


# Retrieve second platform IDs (GPL) associated with the GSE
gpl_2 <- names(GPLList(gse))[[2]]

print("Second Platform:")
#Retrieve detailed information about the platform used in the GEO series
gpl_2_info <- Meta(getGEO(gpl_2))

gpl_2_info$title

gpl_2_info$last_update_date

gpl_2_info$organism
```

#### Information on Data Processing:

```{r}
gse@gsms[[1]]@header$data_processing[1]
```

#### GEO Dataset Summary

**Title:** `r gse@header$title`\
**GEO Accession:** `r gse@header$geo_accession`\
**Submission Date:** `r gse@header$submission_date`\
**Last Update:** `r gse@header$last_update_date`

**Platform 1:** `r gpl_1_info$title`\
**Platform 2:** `r gpl_2_info$title`

**PubMed ID:** `r gse@header$pubmed_id`

**Contact Name:** `r gse@header$contact$name`\
**Contact Email:** `r gse@header$contact$email`

#### Supplementary File

There is one supplementary file available for this study and it contains the raw counts for the RNASeq dataset.

```{r}
#get the names of the supplementary files
sfilenames = getGEOSuppFiles(data_set_geoid, fetch_files = FALSE)
sfilenames$fname

# No need to worry about which file to use as there is only one, but this is here for convenience in later analysis 
data_filename <- sfilenames$fname[1]
data_filename
```

## Data Assesment

- code in this section is adapted from Lecture 4 [@lec4]
#### Get Expression Data

```{r}
#Download to current directory
download_dir <- file.path(getwd())

# Check to see if the file exists already before you download them
# Only download files that we don't have from the set of supplementary files

# Identify missing files based on their presence in the download directory
missing_files <- sfilenames$fname[!unlist(
  lapply(sfilenames$fname, function(x) {
    file.exists(file.path(download_dir, data_set_geoid, x))
  })
)]

# Download missing files
if (length(missing_files) > 0) {
  for (i in 1:length(missing_files)) {
    # Get the supplementary files from GEO
    sfiles <- getGEOSuppFiles(data_set_geoid,
                              filter_regex = missing_files[i],
                              baseDir = download_dir,
                              fetch_files = TRUE)
  }
}

```

#### Read the Data

```{r}
# Read the data table from a specified file path within the download directory
luad_rnaseq_data <- read.table(
  file.path(download_dir, data_set_geoid, data_filename),  # Construct the full path to the file
  header = TRUE,   # Specify that the first row of the file contains column headers
  check.names = TRUE  # Ensure that column names are valid R names and adjust if necessary
)

# Display the dimensions of the luad_data data frame to understand its structure
dim(luad_rnaseq_data)

# Generate an HTML-formatted table using 'kable' from the 'knitr' package
# Only look at the first 7 rows and columns
kable(luad_rnaseq_data[1:7,1:7], format = "html")
```

#### Dataset Size

```{r}
nrow(luad_rnaseq_data)
```

This data contains 57445 rows genes which sounds like a good length for RNASeq data.



#### Collect Addition Annotation

This provides information on the sample description / cell type, the tissue type, the cell line, and GSM.

```{r}
# Extract all sample information from the GSE object
list_of_samples <- gse@gsms

# Create a data frame containing the title and characteristics of each sample
samples_type <- do.call(rbind,
    lapply(list_of_samples, function(x) {
        c(x@header$title, x@header$characteristics_ch1)
    })
)

head(samples_type, 3)
```

Rename different sample groups and replace with descriptive column names:

```{r}
# convert to a data frame
sample_type_df <- as.data.frame(samples_type, stringsAsFactors = FALSE)

colnames(sample_type_df) <- c("Sample Type", "Tissue Type", "Cell Line", "Cell Type", "Batch")

sample_type_df[,'Tissue Type'] <- gsub(sample_type_df[,'Tissue Type'],
                                             pattern = "tissue: ",
                                             replacement = "")

sample_type_df[,'Cell Line'] <- gsub(sample_type_df[,'Cell Line'],
                                             pattern = "cell line: ",
                                             replacement = "")

sample_type_df[,'Cell Type'] <- gsub(sample_type_df[,'Cell Type'],
                                             pattern = "cell type: ",
                                             replacement = "")

sample_type_df[,'Batch'] <- gsub(sample_type_df[,'Batch'],
                                             pattern = "batch: ",
                                             replacement = "")

knitr::kable(sample_type_df, format = "html", align = "c")


# Map column names of date to sample name
# colnames(luad_rnaseq_data)[3:28] <- sample_type_df$"Sample Type"
# Actually nvm cause it would be too long
```

####Analyzing Column Names

```{r}
colnames(luad_rnaseq_data)[1:28]
```

There are a total number of 26 samples in the dataset. From the above I can (safely) assume:

-   LUAD refers to the 4 Human Tumor samples
-   PDO without MDO refers to the 17 Patient Derived Organoid samples
-   PDO23_MDO refers to the 5 Metastasis Derived Organoid samples

To verify this observation:

```{r}
# Count unique sample types in the Sample Type column
number_of_unique_samples <- length(unique(sample_type_df$"Sample Type"))
number_of_unique_samples


# Group by 'Cell Type' and count unique 'Sample Type'
sample_counts_per_cell_type <- sample_type_df %>%
  group_by(`Cell Type`) %>%
  summarise(Unique_Samples = n_distinct(`Sample Type`))

# Print the results
print(sample_counts_per_cell_type)

```


## Data Mapping

Fortunately, for the `luad_rnaseq_data`, it appears that the `SYMBOL` column is already mapped to gene symbols, which are often referred to as HUGO Gene Nomenclature Committee (HGNC) symbols. These symbols are standard identifiers for genes in human biology and are used to ensure consistency and accuracy.

To verify the mapping already present in the dataset, I will double check the first five rows in the `luad_rnaseq_data` manually

- code in this section is adapted from Lecture 5 identifier_mapping [@lec5map]

* this chunk will probably take around 3 min to run
```{r}
# Extract the first three Ensembl IDs from row names
ensembl_ids <- (luad_rnaseq_data$ENSEMBL)[1:5]
# Remove any version numbers from the Ensembl IDs
ensembl_ids <- sub("\\..*$", "", ensembl_ids)

# Connect to the Ensembl database
ensembl <- useMart("ensembl", dataset = "hsapiens_gene_ensembl")

# Get gene symbols using the cleaned Ensembl IDs
gene_info <- getBM(attributes = c('ensembl_gene_id', 'hgnc_symbol'), 
                   filters = 'ensembl_gene_id', 
                   values = ensembl_ids, 
                   mart = ensembl)

# Print the retrieved gene information
print(gene_info)

```

This matches what is in the dataset, so no further mapping is needed.

## Data Cleaning

See if there are missing values for mapped symbols:

```{r}
# Check for empty strings or NA values in the SYMBOL column
missing_symbols <- luad_rnaseq_data[luad_rnaseq_data$SYMBOL == "" | is.na(luad_rnaseq_data$SYMBOL), ]

# Print the rows with missing SYMBOLs
print(missing_symbols)

# Count the number of genes with missing SYMBOLs
num_missing_symbols <- nrow(missing_symbols)
print(paste("Number of genes with missing SYMBOLs:", num_missing_symbols))
```

See if there are duplicate genes:

```{r}
# Identify duplicates
dup_genes_luad <- luad_rnaseq_data[duplicated(luad_rnaseq_data$SYMBOL) | duplicated(luad_rnaseq_data$SYMBOL, fromLast = TRUE),]

# Display the dimensions to understand the updated structure
dim(dup_genes_luad)

```

There are indeed duplicates so to remove them:
```{r}

# Remove duplicates and keep the first occurrence
luad_rnaseq_data_unique <- luad_rnaseq_data %>%
  distinct(SYMBOL, .keep_all = TRUE)

# Display the dimensions to understand the updated structure
dim(luad_rnaseq_data_unique)
```

As there are many PDO samples, I will only keep the first 5 for this analysis due to computational space and resource constrains.

```{r}

columns_to_keep <- c("ENSEMBL", "SYMBOL", "LUAD16T", "LUAD18T", "LUAD1T", "LUAD23T",
                     "PDO1", "PDO2", "PDO4", "PDO5", "PDO6", "PDO23_MDO1_DIAPH", "PDO23_MDO1_Liver", "PDO23_MDO2_Brain", "PDO6_MDO_Brain", "PDO23_MDO3_GB")

# Subset the data frame
luad_rnaseq_subset <- luad_rnaseq_data_unique[, columns_to_keep]

# Check the structure of the new data frame
dim(luad_rnaseq_subset)

knitr::kable(luad_rnaseq_subset[1:7,1:14], format = "html", align = "c")

```

Before proceeding to filter for outliers, it's beneficial to visualize the data using plots such as histograms or boxplots:
- code in this section is adapted from Lecture 5 normalization [@lec5norm]
```{r}

# Basic boxplot
boxplot(luad_rnaseq_subset[,3:ncol(luad_rnaseq_subset)],
        main = "Expression Levels in LUAD Samples",
        ylab = "Expression",
        xlab = "Samples",
        las = 2, # Makes the sample names vertical
        col = rainbow(ncol(luad_rnaseq_subset)-2)) # Adding some color

```

For a density plot, since I am interested in the expression levels, I will have to ensure that the data subset (luad_rnaseq_subset) only contains numeric data: 
```{r}

rownames(luad_rnaseq_subset) <- luad_rnaseq_subset$SYMBOL

# Numeric only
luad_data_numeric <- luad_rnaseq_subset[, 3:ncol(luad_rnaseq_subset)]

```

Before plotting, adding a log2 transformation is particularly useful when dealing with RNA-seq data or any other data types where expression levels can vary over several orders of magnitude.
```{r}
# Add 1 to avoid log2(0)
luad_data_numeric_adjusted <- luad_data_numeric + 1

# Apply log2 transformation
luad_data_log2 <- log2(luad_data_numeric_adjusted)

# Display the first few rows of the log2-transformed data
head(luad_data_log2)


# Melt the dataframe to a long format for easier use with ggplot
luad_data_long_log2 <- melt(luad_data_log2, variable.name = "Sample", value.name = "Log2Expression")
# luad_data_long <- melt(luad_rnaseq_subset, variable.name = "Sample", value.name = "Expression")


# Create the density plot
ggplot(luad_data_long_log2, aes(x = Log2Expression, fill = Sample)) +
  geom_density(alpha = 0.5) +  # Adjust alpha for transparency to see overlapping areas
  labs(title = "Density of Log2 Expression Levels across LUAD Samples",
       x = "Log2 Expression",
       y = "Density") +
  theme_minimal() +
  theme(legend.position = "right")  # Adjust legend position



```

#### Outliers Anlaysis

Will use the interquartile range (IQR) to identify and potentially remove outliers. While not always the best choice for complex statistical analyses, it can be highly beneficial for preliminary analysis to quickly identify outliers and understand the distribution of data.

```{r}
# Calculate the first and third quantiles (25th and 75th percentiles), and the IQR for each sample (column)
quantile_1 <- apply(luad_data_log2, 2, quantile, 0.25)
quantile_3 <- apply(luad_data_log2, 2, quantile, 0.75)
iqr <- quantile_3 - quantile_1

# Calculate the lower and upper bounds for identifying outliers in each sample
lower_bound <- quantile_1 - (1.5 * iqr)
upper_bound <- quantile_3 + (1.5 * iqr)

# Check if data is within the outlier bounds for each sample
within_range <- luad_data_log2 >= lower_bound & luad_data_log2 <= upper_bound

# Calculate the percentage of data points in each sample that are not outliers
outlier_percent <- (dim(luad_data_log2)[1] - colSums(within_range)) / dim(luad_data_log2)[1]

# Create a data frame with the lower bound, upper bound, and outlier percentage for easier interpretation
outlier_analysis <- data.frame(
  Lower_Bound = lower_bound,
  Upper_Bound = upper_bound,
  Outlier_Percent = outlier_percent
)

# Print the results for review
print(outlier_analysis)


# Convert the row names to a column for ggplot
outlier_analysis$Sample <- rownames(outlier_analysis)

# Create a bar plot for outlier percentages
ggplot(outlier_analysis, aes(x = Sample, y = Outlier_Percent, fill = Outlier_Percent)) +
  geom_bar(stat = "identity") +
  labs(title = "Outlier Percentages by Sample",
       x = "Sample",
       y = "Percentage of Outliers") +
  scale_fill_gradient(low = "blue", high = "red") + # Color gradient from low to high percentage
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 

```
The plot displays the proportion of outliers detected in each sample using the interquartile range (IQR) method, where outliers are defined as those data points lying beyond 1.5 times the IQR from the first (25th percentile) and third quartiles (75th percentile).

From the visualization, it's evident that the sample LUAD18T stands out with a significantly higher percentage of outliers compared to other samples, indicating potential issues such as experimental variability or genuine biological variation. Most other samples show a relatively consistent range of outlier percentages, suggesting uniformity in data characteristics or quality.

The IQR method is suggested from the following forum: 
https://stats.stackexchange.com/questions/200534/is-it-ok-to-remove-outliers-from-data/200923

```{r}
# Create a mask to identify values within the outlier bounds
mask <- luad_data_log2 >= lower_bound & luad_data_log2 <= upper_bound

# Apply the mask to the data to filter out outliers
luad_data_cleaned <- luad_data_log2 * mask

# Replace outliers (now 0) with NA for clarity or for further handling like imputation
luad_data_cleaned[luad_data_cleaned == 0] <- NA

# Overview of the cleaned data
head(luad_data_cleaned)


# Calculate the new mean and median without outliers
clean_means <- apply(luad_data_cleaned, 2, mean, na.rm = TRUE)
clean_medians <- apply(luad_data_cleaned, 2, median, na.rm = TRUE)

# Create a summary dataframe
summary_stats <- data.frame(Mean = clean_means, Median = clean_medians)
print(summary_stats)

# Calculate the number of outliers for each sample
num_outliers <- dim(luad_data_log2)[1] - colSums(within_range)

# Calculate the total number of outliers removed across all samples
total_outliers_removed <- sum(num_outliers)

# Print the total number of outliers removed
print(paste("Total number of outlier fields removed:", total_outliers_removed))
```
## Data Normalization

#### Visualizing Distribution

Boxplot:


```{r}

data2plot <- luad_data_cleaned

# Create a boxplot of the log-transformed data
boxplot(
  data2plot, xlab = "Samples", ylab = "log2 TPM",
  las = 2, cex = 0.5,
  cex.lab = 0.5,
  cex.axis = 0.5,
  main = "RNASeq Samples"
)

# Calculate the overall median across all samples, ensuring to remove NA values
overall_median <- median(apply(data2plot, 2, function(x) median(x, na.rm = TRUE)), na.rm = TRUE)

# Adding the median line to the boxplot
abline(h = overall_median, col = "green", lwd = 0.6, lty = "dashed")

```

```{r}
# Calculate density for each column, excluding NA values
counts_density <- apply(data2plot, 2, function(x) {
  if (all(is.na(x))) { 
    return(NULL)  # Return NULL if all values are NA
  } else {
    return(density(na.omit(x)))  # Use na.omit to exclude NA values
  }
})

  #calculate the limits across all the samples
    xlim <- 0; ylim <- 0
    for (i in 1:length(counts_density)) {
      xlim <- range(c(xlim, counts_density[[i]]$x));
      ylim <- range(c(ylim, counts_density[[i]]$y))
    }
    
    cols <- rainbow(length(counts_density))
    ltys <- rep(1, length(counts_density))
        
    #plot the first density plot to initialize the plot
    plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n",
        ylab="Smoothing density of log2-CPM",
        main="", cex.lab = 0.85)

    #plot each line
    for (i in 1:length(counts_density))
      lines(counts_density[[i]], col=cols[i], lty=ltys[i])

    #create legend
    legend("topright", colnames(data2plot),
        col=cols, lty=ltys, cex=0.75,
        border ="blue", text.col = "green4",
        merge = TRUE, bg = "gray90")



```

#### edgeR 

##### Trimmed Mean of M-values (TMM) 
To perform normalization in edgeR, I will be creating a DGEList Object, and grouping the data by cell types. 

```{r}
# Extracting the group information for cell type from luad_data_numeric
groups <- as.factor(ifelse(grepl("LUAD", colnames(luad_data_numeric)), "LUAD",
                  ifelse(grepl("^PDO[0-9]+$", colnames(luad_data_numeric)), "PDO",
                         ifelse(grepl("PDO", colnames(luad_data_numeric)), "PDO_MDO", NA))))


# Create DGEList from your data matrix
dge <- DGEList(counts = luad_data_numeric, group=groups)

# Filter out lowly expressed genes
keep <- filterByExpr(dge)
dge <- dge[keep,]

# Calculate normalization factors
dge <- calcNormFactors(dge, method = "TMM")

# Calculate raw CPM
cpm_data <- cpm(dge)


# Viewing the first few rows of the normalized data
head(cpm_data)

# Adding 1 to the counts to avoid log of zero if not already done
normalized_luad_log2 <- log2(cpm_data + 1)
```

#### Recalculate distribution and density:

```{r}

#Boxplot
# Create a boxplot of the log-transformed data
boxplot(
  normalized_luad_log2, xlab = "Samples", ylab = "log2 TPM",
  las = 2, cex = 0.5,
  cex.lab = 0.5,
  cex.axis = 0.5,
  main = "RNASeq Samples"
)

# Calculate the overall median across all samples, ensuring to remove NA values
overall_median <- median(apply(normalized_luad_log2, 2, function(x) median(x, na.rm = TRUE)), na.rm = TRUE)

# Adding the median line to the boxplot
abline(h = overall_median, col = "green", lwd = 0.6, lty = "dashed")



# Distribution
counts_density <- apply(normalized_luad_log2, 2, function(x) {
  if (all(is.na(x))) { 
    return(NULL)  # Return NULL if all values are NA
  } else {
    return(density(na.omit(x)))  # Use na.omit to exclude NA values
  }
})

  #calculate the limits across all the samples
    xlim <- 0; ylim <- 0
    for (i in 1:length(counts_density)) {
      xlim <- range(c(xlim, counts_density[[i]]$x));
      ylim <- range(c(ylim, counts_density[[i]]$y))
    }
    
    cols <- rainbow(length(counts_density))
    ltys <- rep(1, length(counts_density))
        
    #plot the first density plot to initialize the plot
    plot(counts_density[[1]], xlim=xlim, ylim=ylim, type="n",
        ylab="Smoothing density of log2-CPM",
        main="", cex.lab = 0.85)

    #plot each line
    for (i in 1:length(counts_density))
      lines(counts_density[[i]], col=cols[i], lty=ltys[i])

    #create legend
    legend("topright", colnames(normalized_luad_log2),
        col=cols, lty=ltys, cex=0.75,
        border ="blue", text.col = "green4",
        merge = TRUE, bg = "gray90")



```

```{r}

# Plotting MDS
plotMDS(dge, col=as.numeric(dge$samples$group), pch=20, cex=1.5)  # Adjust point type and size
legend("topright", legend=levels(dge$samples$group), col=1:length(levels(dge$samples$group)), pch=20)

```
#### Final data
```{r}
dim(normalized_luad_log2)

```

## Interpret and Document

**Why is the dataset of interest to you?** 

I chose this dataset because I was always interested in cancer research. Also, I had been working with LUAD relate projects in the past and I want to continue the exploration.

**What are the control and test conditions of the dataset?** 

PDOs and Metastasis-derived Organoids (MDOs)are primarily the test groups. They are derived from patient tumors. The Human Tumor Samples, or, original tumor samples from which PDOs are derived serve as the control.

**How many samples in each of the conditions of your dataset?** 

There are 17 Patient Derived Organoid samples, 5 Metastasis Derived Organoid samples, and 4 Human Tumor Samples. I subsetted the data for preliminary analysis so in my assessment I included 5 Patient Derived Organoid samples, 5 Metastasis Derived Organoid samples, and 4 Human Tumor Samples.

**Were there expression values that were not unique for specific genes? How did you handle these?** 

Upon checking for duplicates based on the `SYMBOL column`, I identified 2,322 duplicated entries, indicating that some genes had multiple occurrences in the dataset. Using the `distinct()` function from the `dplyr` package, the first occurrence of each unique gene symbol is kept. After filtering, the dataset was reduced to 55,401 unique genes.

**Were there expression values that could not be mapped to current HUGO symbols?** 

No, there were no expression values that could not be mapped to current HUGO symbols. The dataset provided by the study already mapped all expression to their symbols and there does not seem to be any empty ones as per my analysis. 

***Were there any outliers in your dataset? How were they handled in the originating paper? How many outliers were removed?*** 

In the original paper, the authors do not mention whether the outliers were removed, not the way they were handled. I identified outliers sing the IQR method. I applied a masking approach, replacing values outside the acceptable range with `NA`. After filtering, the mean and median expression levels were recalculated. A total of 36810 outlier feilds are removed.

***How did you handle replicates?*** 

There are no technical replicates are all samples are the same run. However, there are multiple biological replicates in each conditions. Biological replicates were grouped together for analysis using edgeR. 

***What is the final coverage of your dataset?***

The final coverage is 17195 genes over 14 samples. 

## References
The R packages used in the analysis include: `GEOquery` [@GEOquery], `edgeR` [@edgeR], `reshape2` [@reshape2], `biomaRt` [@BioMart],  `ggplot2` [@ggplot2], `dplyr` [@dplyr], `tidyr` and `knitr` [@knitr].